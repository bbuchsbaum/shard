% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/dispatch.R
\name{dispatch_chunks}
\alias{dispatch_chunks}
\title{Dispatch Chunks to Worker Pool}
\usage{
dispatch_chunks(
  chunks,
  fun,
  ...,
  pool = NULL,
  health_check_interval = 10L,
  max_retries = 3L,
  timeout = 3600,
  scheduler_policy = NULL,
  on_result = NULL,
  store_results = TRUE,
  retain_chunks = TRUE
)
}
\arguments{
\item{chunks}{List of chunk descriptors. Each chunk will be passed to \code{fun}.}

\item{fun}{Function to execute. Receives (chunk, ...) as arguments.}

\item{...}{Additional arguments passed to \code{fun}.}

\item{pool}{A \code{shard_pool} object. If NULL, uses the current pool.}

\item{health_check_interval}{Integer. Check pool health every N chunks (default 10).}

\item{max_retries}{Integer. Maximum retries per chunk before permanent failure (default 3).}

\item{timeout}{Numeric. Seconds to wait for each chunk (default 3600).}

\item{scheduler_policy}{Optional list of scheduling hints (advanced). Currently:
\itemize{
\item \code{max_huge_concurrency}: cap concurrent chunks with \code{footprint_class=="huge"}.
}}

\item{on_result}{Optional callback (advanced). If provided, called on the
master process as \code{on_result(tag, value, worker_id)} for each successful
chunk completion. Used by \code{\link[=shard_reduce]{shard_reduce()}} to stream reductions.}

\item{store_results}{Logical (advanced). If FALSE, successful chunk values are
not retained in the returned \code{results} list (streaming use cases).}

\item{retain_chunks}{Logical (advanced). If FALSE, completed chunk descriptors
are stored minimally (avoids retaining large shard lists in memory).}
}
\value{
A \code{shard_dispatch_result} object with results and diagnostics.
}
\description{
Executes a function over chunks using the worker pool with supervision.
Handles worker death and recycling transparently by requeuing failed chunks.
}
