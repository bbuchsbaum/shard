% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/shard_map.R
\name{shard_map}
\alias{shard_map}
\title{Parallel Execution with shard_map}
\usage{
shard_map(
  shards,
  fun = NULL,
  borrow = list(),
  out = list(),
  kernel = NULL,
  scheduler_policy = NULL,
  workers = NULL,
  chunk_size = 1L,
  profile = c("default", "memory", "speed"),
  mem_cap = "2GB",
  recycle = TRUE,
  cow = c("deny", "audit", "allow"),
  seed = NULL,
  diagnostics = TRUE,
  packages = NULL,
  init_expr = NULL,
  timeout = 3600,
  max_retries = 3L,
  health_check_interval = 10L
)
}
\arguments{
\item{shards}{A \code{shard_descriptor} from \code{\link[=shards]{shards()}}, or an integer N to
auto-generate shards.}

\item{fun}{Function to execute per shard. Receives the shard descriptor
as first argument, followed by borrowed inputs and outputs. You can also
select a registered kernel via \verb{kernel=} instead of providing \verb{fun=}.}

\item{borrow}{Named list of shared inputs. These are exported to workers
once and reused across shards. Treated as read-only by default.}

\item{out}{Named list of output buffers (from \code{buffer()}). Workers write
results directly to these buffers.}

\item{kernel}{Optional. Name of a registered kernel (see \code{\link[=list_kernels]{list_kernels()}}).
If provided, \code{fun} must be NULL.}

\item{scheduler_policy}{Optional list of scheduling hints (advanced). Currently:
\itemize{
\item \code{max_huge_concurrency}: cap concurrent chunks whose kernel footprint is
classified as \code{"huge"} (see \code{\link[=register_kernel]{register_kernel()}}).
}}

\item{workers}{Integer. Number of worker processes. If NULL, uses existing
pool or creates one with \code{detectCores() - 1}.}

\item{chunk_size}{Integer. Shards to batch per worker dispatch (default 1).
Higher values reduce RPC overhead but may hurt load balancing.}

\item{profile}{Execution profile: \code{"default"}, \code{"memory"} (aggressive recycling),
or \code{"speed"} (minimal overhead).}

\item{mem_cap}{Memory cap per worker (e.g., "2GB"). Workers exceeding this
are recycled.}

\item{recycle}{Logical or numeric. If TRUE, recycle workers on RSS drift.
If numeric, specifies drift threshold (default 0.5 = 50\% growth).}

\item{cow}{Copy-on-write policy for borrowed inputs: \code{"deny"} (error on mutation),
\code{"audit"} (detect and flag), or \code{"allow"} (permit with tracking).}

\item{seed}{Integer. RNG seed for reproducibility. If NULL, no seed is set.}

\item{diagnostics}{Logical. Collect detailed diagnostics (default TRUE).}

\item{packages}{Character vector. Additional packages to load in workers.}

\item{init_expr}{Expression to evaluate in each worker on startup.}

\item{timeout}{Numeric. Seconds to wait for each shard (default 3600).}

\item{max_retries}{Integer. Maximum retries per shard on failure (default 3).}

\item{health_check_interval}{Integer. Check worker health every N shards (default 10).}
}
\value{
A \code{shard_result} object containing:
\itemize{
\item \code{results}: List of results from each shard (if fun returns values)
\item \code{failures}: Any permanently failed shards
\item \code{diagnostics}: Timing, memory, and worker statistics
\item \code{pool_stats}: Pool-level statistics
}
}
\description{
Core parallel execution engine with supervision, shared inputs, and output buffers.

Executes a function over shards in parallel with worker supervision,
shared inputs, and explicit output buffers. This is the primary entry
point for shard's parallel execution model.
}
\examples{
\dontrun{
# Simple parallel computation
blocks <- shards(1000, workers = 4)
result <- shard_map(blocks, function(shard) {
  sum(shard$idx^2)
}, workers = 4)

# With shared inputs
X <- matrix(rnorm(1e6), nrow = 1000)
blocks <- shards(ncol(X), workers = 4)
result <- shard_map(blocks,
  borrow = list(X = X),
  fun = function(shard, X) {
    colMeans(X[, shard$idx, drop = FALSE])
  },
  workers = 4
)
}
}
