% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/table_stream.R
\name{stream_reduce}
\alias{stream_reduce}
\title{Stream over row-groups/datasets and reduce}
\usage{
stream_reduce(x, f, init, combine, ...)
}
\arguments{
\item{x}{A \code{shard_row_groups} or \code{shard_dataset} handle.}

\item{f}{Function \verb{(chunk, ...) -> value} producing a per-partition value.}

\item{init}{Initial accumulator value.}

\item{combine}{Function \verb{(acc, value) -> acc} to update the accumulator.}

\item{...}{Passed to \code{f()}.}
}
\value{
The final accumulator.
}
\description{
Applies \code{f()} to each partition (row-group) and combines results with
\code{combine()} into a single accumulator. This keeps peak memory bounded by the
largest single partition (plus your accumulator).
}
